{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea92ff31-bfbb-4da5-b7d8-4e0b58528fe7",
   "metadata": {},
   "source": [
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"images/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>\n",
    "\n",
    "\n",
    "# <a name=\"0\">MLU Advanced Prompt Engineering for LLMs</a>\n",
    "## <a name=\"0\">Lab 6: Guardrails</a>\n",
    "\n",
    "This notebook demonstrates how to use various techniques that can help improve the safety and security of LLM-backed applications. The coding examples cover guardrails that can filter certain keywords or that leverage metrics to decide if content is harmful.\n",
    "\n",
    "1. <a href=\"#1\">Install and import libraries</a>\n",
    "2. <a href=\"#2\">Set up Bedrock for inference</a>\n",
    "3. <a href=\"#3\">Guardrails</a>\n",
    "    - <a href=\"#31\">Keyword-based filtering</a>\n",
    "    - <a href=\"#32\">Metric-based filtering</a>\n",
    "    - <a href=\"#33\">LLM-based filtering</a>\n",
    "4. <a href=\"#4\">Conclusion</a>\n",
    "    \n",
    "Please work top to bottom of this notebook and don't skip sections as this could lead to error messages due to missing code.\n",
    "\n",
    "---\n",
    "\n",
    "<br/>\n",
    "You will be presented with coding activities to check your knowledge and understanding throughout the notebook whenever you see the MLU robot:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45807b08-06db-49d7-8cc4-4edae4ddcbaf",
   "metadata": {},
   "source": [
    "<img style=\"display: block; margin-left: auto; margin-right: auto;\" src=\"./images/activity.png\" alt=\"Activity\" width=\"125\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc1675-295d-4b62-908c-d87ac9e241f4",
   "metadata": {},
   "source": [
    "## <a name=\"1\">1. Install and import libraries</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's start by installing all required packages as specified in the `requirements.txt` file and importing several libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc03394-3d26-47e0-8561-f235923bcf7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -q --upgrade pip\n",
    "!pip3 install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef767883-c218-4b89-9a6d-95f026c95341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings, sys\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277c29de-96fc-481f-a9dc-7c612adb7446",
   "metadata": {},
   "source": [
    "## <a name=\"2\">2. Set up Bedrock for inference</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "To get started, set up Bedrock and instantiate an active runtime to query LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4397250-5b71-49fc-bb69-c922b910a164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# define the bedrock-runtime client that will be used for inference\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")\n",
    "\n",
    "# define the model\n",
    "bedrock_model_id = \"anthropic.claude-v1\"\n",
    "\n",
    "# each model has a different set of inference parameters\n",
    "inference_modifier = {\n",
    "    \"max_tokens_to_sample\": 300,\n",
    "    \"temperature\": 0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman:\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853f68a0-91f5-4380-a65c-05c29e349150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "# define the langchain module with the selected bedrock model\n",
    "bedrock_llm = Bedrock(\n",
    "    model_id=bedrock_model_id,\n",
    "    client=bedrock_runtime,\n",
    "    model_kwargs=inference_modifier,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec05c04-f839-404b-82b3-d84a9e948a93",
   "metadata": {},
   "source": [
    "Next, use Bedrock for inference to test everything works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef6b89ae-b830-475b-8061-975515597bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm doing well, thanks for asking! My name is Claude.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_llm(\"\\n\\nHuman: How are you doing today? \\n\\nAssistant:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e5e89-b6b5-4dc4-93cf-245ecbbf5e78",
   "metadata": {},
   "source": [
    "## <a name=\"3\">3. Guardrails</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512862ea-d78b-4e7f-a564-10df5ddfa5c5",
   "metadata": {},
   "source": [
    "### Dealing with prompt injections\n",
    "What can be done to prevent prompt injections? In this section, you will be working with guardrails.\n",
    "\n",
    "Whenever guardrails flag a potentially harmful output, there are several strategies to deal with this and to improve security and safety of LLMs:\n",
    "- refuse to perform task (prompt refusal)\n",
    "- perform task, but add disclaimer\n",
    "- summarize result in a harmless way\n",
    "- explain and perform a similar but harmless task\n",
    "\n",
    "Let's have a look at [Guardrails.ai](https://docs.guardrailsai.com/) in combination with [LangChain](https://www.langchain.com/):\n",
    "\n",
    "#### Guardrails\n",
    "To get started with [Guardrails.ai](https://docs.guardrailsai.com/) you need a RAIL (Reliable AI markup Language) spec XML:\n",
    "\n",
    "```\n",
    "<rail version=\"0.1\">\n",
    "\n",
    "    <output> \n",
    "    ...\n",
    "    </output>\n",
    "\n",
    "\n",
    "    <prompt> \n",
    "    ...\n",
    "    </prompt>\n",
    "\n",
    "</rail>\n",
    "```\n",
    "\n",
    "The main components are:\n",
    "- `output` contains information about the expected output of the LLM such as overall structure of the LLM output, type info for each field, and the quality criteria for each field and the corrective action to be taken in case quality criteria is not met\n",
    "- `prompt` contains the high level instructions that are sent to the LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0964422d-14e0-4f9c-a4c9-613b2d2d1390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rail_spec_sample = \"\"\"\n",
    "<rail version=\"0.1\">\n",
    "    <output>\n",
    "        <object name=\"product_info\">\n",
    "            <string description=\"Brand name of product\" name=\"brand\"></string>\n",
    "            <float description=\"Price of product\" name=\"price\" format=\"valid-range: 0 1000\"></float>\n",
    "            <string description=\"Description of product\" name=\"description\"></string>\n",
    "        </object>\n",
    "    </output>\n",
    "\n",
    "    <prompt>\n",
    "    \\n\\nHuman: Given the following text snippet, extract a dictionary that contains the product's information.\n",
    "    ${product_notes}\n",
    "    ${gr.complete_json_suffix}\n",
    "    \\n\\nAssistant:\n",
    "    </prompt>\n",
    "</rail>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c658a0d-b047-40e2-aaba-38328ed45034",
   "metadata": {},
   "source": [
    "#### LangChain\n",
    "\n",
    "Let's include the RAIL spec in the code to add a layer of security around LangChain components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1daeaa6-1486-4195-bf20-5e63dc2beae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import guardrails as gd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f10005-7419-4c00-911d-7dd76242815f",
   "metadata": {},
   "source": [
    "The `GuardrailsOutputParser` contains a `Guard` object, which can be used to access the prompt and output schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d864acb5-e088-4359-9e61-2fc727319eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import GuardrailsOutputParser\n",
    "\n",
    "output_parser_simple = GuardrailsOutputParser.from_rail_string(\n",
    "    rail_spec_sample, api=bedrock_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e302346-e704-4135-86d5-3a01e7eb7d09",
   "metadata": {},
   "source": [
    "You can now create a [LangChain](https://www.langchain.com/) `PromptTemplate` from this output parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba7bcb58-2c32-47b0-ad26-6bf84d1c4eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_simple = PromptTemplate(\n",
    "    template=output_parser_simple.guard.prompt.escape(),\n",
    "    input_variables=output_parser_simple.guard.prompt.variable_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc5860-3e2e-4fc3-87b3-723bcc3c984f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally, pass the prompt to Bedrock and retrieve the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7e6361f-43f6-408b-8ce6-222d6a568fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extract_info = \"\"\"19.99. A cold-weather Carhartt classic hat that is made of stretchy rib knit that's soft to the touch.\"\"\"\n",
    "\n",
    "output_simple = bedrock_llm(\n",
    "    prompt_simple.format_prompt(product_notes=extract_info).to_string()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ece7808f-944f-42ef-9aed-9d3eb179c34a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'product_info'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'brand'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Carhartt'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'price'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19.99</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"A cold-weather Carhartt classic hat that is made of stretchy rib knit that's soft to the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">touch.\"</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'product_info'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'brand'\u001b[0m: \u001b[32m'Carhartt'\u001b[0m,\n",
       "        \u001b[32m'price'\u001b[0m: \u001b[1;36m19.99\u001b[0m,\n",
       "        \u001b[32m'description'\u001b[0m: \u001b[32m\"A cold-weather Carhartt classic hat that is made of stretchy rib knit that's soft to the \u001b[0m\n",
       "\u001b[32mtouch.\"\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "\n",
    "print(output_parser_simple.parse(output_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b200d7f-067a-4435-b522-53c83509791e",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Try different prompts to extract product information.</b> For example, you could try this snippet of text and parse it: </br> <code>\"Premier Protein Shake with 24 Vitamins Minerals Nutrients to Support Immune Health. Price:$28.48 ($0.21 / Fl Oz)\"</code>\n",
    "</div>\n",
    "<img style=\"display: block; margin-left: auto; margin-right: auto;\" src=\"./images/activity.png\" alt=\"Activity\" width=\"125\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21fe4148-1f61-477f-b464-fa4402360b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############## CODE HERE ####################\n",
    "\n",
    "\n",
    "############## END OF CODE ##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d147b2-1982-4c24-9c07-daa0be3be527",
   "metadata": {},
   "source": [
    "### <a name=\"31\">3.1. Keyword-based input filtering</a>\n",
    "(<a href=\"#3\">Go to \"Guardrails\"</a>)\n",
    "\n",
    "Keyword-based filtering checks a users' input for forbidden words or phrases. If keywords are identified, the prompt will be rejected. However, this can be bypassed by using alternative words and might be difficult to implement across different tasks, domains etc.\n",
    "\n",
    "[Guardrails.ai](https://docs.guardrailsai.com/) offers different strategies on how to deal with failed validation checks; e.g. filtering, fixing, asking the LLM again. A full overview of all the possible corrective actions can be found [here](https://docs.guardrailsai.com/concepts/output/#specifying-corrective-actions). In the code snippet below, you will see a custom validator that checks for keywords in the LLM output and replaces them with `***`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0adca6e0-28cc-45c2-af75-8db1e72bd850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from guardrails.validators import (\n",
    "    Validator,\n",
    "    register_validator,\n",
    "    ValidationResult,\n",
    "    PassResult,\n",
    "    FailResult,\n",
    ")\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "@register_validator(name=\"is-keyword-free\", data_type=\"string\")\n",
    "class IsKeywordFree(Validator):\n",
    "    def validate(self, value: Any, metadata: Dict) -> ValidationResult:\n",
    "        kw_list = [\"hate\"]\n",
    "        # check for forbidden words\n",
    "        if any(kw in value for kw in kw_list):\n",
    "            # replace forbidden words in output with ***\n",
    "            for kw in kw_list:\n",
    "                censored_text = value.replace(kw, \"***\")\n",
    "            # return result\n",
    "            return FailResult(\n",
    "                error_message=f\"Expression '{value}' contains forbidden keyword.\",\n",
    "                fix_value=censored_text,\n",
    "            )\n",
    "        # else return pass\n",
    "        return PassResult()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89688894-c08a-4047-b880-8a424cc4ae21",
   "metadata": {},
   "source": [
    "Let's translate a statement this time; inside the XML you need to specify `format` and the action to take `on-fail`. For `format` you pass in the custom validator that you just instantiated; for the corrective action, try `fix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ec4d23a-452f-44fc-967f-a71355abfeeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rail_spec_filter = \"\"\"\n",
    "<rail version=\"0.1\">\n",
    "    <output>\n",
    "        <string description=\"Translate to English\" format=\"is-keyword-free\" name=\"translated_statement\" on-fail-is-keyword-free=\"fix\"></string>\n",
    "    </output>\n",
    "\n",
    "    <prompt>\n",
    "    \\n\\nHuman: Translate the given statement into English language:\n",
    "    ${statement_to_be_translated}\n",
    "    ${gr.complete_json_suffix}\n",
    "    \\n\\nAssistant:\n",
    "    </prompt>\n",
    "\n",
    "</rail>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c2374-1bf4-4e3e-8359-df94ee0e7bb2",
   "metadata": {},
   "source": [
    "Next, you need the `Guard` object; you can create this directly from the RAIL spec or use LangChain again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61cc2e1f-97ea-4fae-bfa2-decd3a62274e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validated Output: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'translated_statement'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I *** you.'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Validated Output: \u001b[1m{\u001b[0m\u001b[32m'translated_statement'\u001b[0m: \u001b[32m'I *** you.'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a Guard object directly from a RAIL string\n",
    "guard_keyword = gd.Guard.from_rail_string(rail_spec_filter)\n",
    "\n",
    "# provide API to Guard and the prompt input\n",
    "raw_llm_response, validated_response = guard_keyword(\n",
    "    llm_api=bedrock_llm,\n",
    "    prompt_params={\"statement_to_be_translated\": \"Ich hasse dich.\"},\n",
    ")\n",
    "\n",
    "# show the output\n",
    "print(f\"Validated Output: {validated_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be46791-c803-4481-a91c-80226ae9c096",
   "metadata": {
    "tags": []
   },
   "source": [
    "Alternatively, you can use LangChain again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85501f44-e719-4eb4-af9b-88304fbd1272",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'translated_statement'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I *** you.'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'translated_statement'\u001b[0m: \u001b[32m'I *** you.'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instantiate the output parser\n",
    "output_parser_filter = GuardrailsOutputParser.from_rail_string(\n",
    "    rail_spec_filter, api=bedrock_llm\n",
    ")\n",
    "\n",
    "# initiate the prompt template\n",
    "prompt_template_filter = PromptTemplate(\n",
    "    template=output_parser_filter.guard.prompt.escape(),\n",
    "    input_variables=output_parser_filter.guard.prompt.variable_names,\n",
    ")\n",
    "\n",
    "# define a sentence to translate\n",
    "translate_this = \"Ich hasse dich.\"\n",
    "\n",
    "# apply the prompt template and call the model\n",
    "output_filter = bedrock_llm(\n",
    "    prompt_template_filter.format_prompt(\n",
    "        statement_to_be_translated=translate_this\n",
    "    ).to_string()\n",
    ")\n",
    "\n",
    "# print the validated result\n",
    "print(output_parser_filter.parse(output_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd7dbaa-29e0-4486-ae10-81a5a81060f2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Write your own custom validator to check that the response length does not exceed a limit.</b> If the limit is exceeded, the LLM should be reasked to create a new and shorter response. You can achieve this by using <code>reask</code> for the <code>on-fail</code> condition.\n",
    "</div>\n",
    "<img style=\"display: block; margin-left: auto; margin-right: auto;\" src=\"./images/activity.png\" alt=\"Activity\" width=\"125\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6bcd86d-d3c5-41a6-ae19-73280a0d32a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############## CODE HERE ####################\n",
    "\n",
    "\n",
    "############## END OF CODE ##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db357e7e-e808-448a-8319-8708a4aae3ca",
   "metadata": {},
   "source": [
    "### <a name=\"32\">3.2. Metric-based input filtering</a>\n",
    "(<a href=\"#3\">Go to \"Guardrails\"</a>)\n",
    "\n",
    "Metric-based filtering uses evaluation metrics like perplexity, toxicity, or polarity to detect unnatural or harmful inputs. A threshold determines if the prompt will be executed. However, metrics are not infallible and there could be significant impact on latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aa73f39-eb78-4341-8276-e95e21d98dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from profanity_check import predict\n",
    "\n",
    "\n",
    "@register_validator(name=\"is-profanity-free\", data_type=\"string\")\n",
    "class IsProfanityFree(Validator):\n",
    "    def validate(self, value: Any, metadata: Dict) -> ValidationResult:\n",
    "        prediction = predict([value])\n",
    "        if prediction[0] == 1:\n",
    "            return FailResult(\n",
    "                error_message=f\"The result contains profanity and will be filtered.\",\n",
    "                fix_value=\"\",\n",
    "            )\n",
    "        return PassResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "404cdc1e-00f2-4abc-8895-17e597157e69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rail_spec_metric = \"\"\"\n",
    "<rail version=\"0.1\">\n",
    "    <output>\n",
    "        <string description=\"Translate to English\" format=\"is-profanity-free\" name=\"translated_statement\" on-fail-is-profanity-free=\"filter\"></string>\n",
    "    </output>\n",
    "\n",
    "    <prompt>\n",
    "    \\n\\nHuman: Translate the given statement into English language:\n",
    "    ${statement_to_be_translated}\n",
    "    ${gr.complete_json_suffix}\n",
    "    \\n\\nAssistant:\n",
    "    </prompt>\n",
    "\n",
    "</rail>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb7ded3f-8980-4c1f-8e33-78668a86552c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validated Output: <span style=\"font-weight: bold\">{}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Validated Output: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "guard_metric = gd.Guard.from_rail_string(rail_spec_metric)\n",
    "\n",
    "raw_llm_response, validated_response = guard_metric(\n",
    "    llm_api=bedrock_llm,\n",
    "    prompt_params={\"statement_to_be_translated\": \"Ich hasse dich.\"},\n",
    ")\n",
    "\n",
    "print(f\"Validated Output: {validated_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "292a697d-14b6-4c68-a52f-d435d1ece1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Logs\n",
       "└── ╭────────────────────────────────────────────────── Step 0 ───────────────────────────────────────────────────╮\n",
       "    │ <span style=\"background-color: #f0f8ff\">╭──────────────────────────────────────────────── Prompt ─────────────────────────────────────────────────╮</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│                                                                                                         │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│                                                                                                         │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│                                                                                                         │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ Human: Translate the given statement into English language:                                             │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│     Ich hasse dich.                                                                                     │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│                                                                                                         │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ Given below is XML that describes the information to extract from this document and the tags to extract │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ it into.                                                                                                │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│                                                                                                         │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ &lt;output&gt;                                                                                                │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│     &lt;string description=\"Translate to English\" format=\"is-profanity-free\" name=\"translated_statement\"/&gt; │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ &lt;/output&gt;                                                                                               │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│                                                                                                         │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│                                                                                                         │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ ONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding  │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g.        │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere,     │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ enter `null`.                                                                                           │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│                                                                                                         │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ Here are examples of simple (XML, JSON) pairs that show the expected behavior:                          │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ - `&lt;string name='foo' format='two-words lower-case' /&gt;` =&gt; `{'foo': 'example one'}`                     │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ - `&lt;list name='bar'&gt;&lt;string format='upper-case' /&gt;&lt;/list&gt;` =&gt; `{\"bar\": ['STRING ONE', 'STRING TWO',     │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ etc.]}`                                                                                                 │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ - `&lt;object name='baz'&gt;&lt;string name=\"foo\" format=\"capitalize two-words\" /&gt;&lt;integer name=\"index\"          │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ format=\"1-indexed\" /&gt;&lt;/object&gt;` =&gt; `{'baz': {'foo': 'Some String', 'index': 1}}`                        │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│                                                                                                         │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│                                                                                                         │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│                                                                                                         │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│ Assistant:                                                                                              │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">│                                                                                                         │</span> │\n",
       "    │ <span style=\"background-color: #f0f8ff\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">╭──────────────────────────────────────────── Message History ────────────────────────────────────────────╮</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">│ ┏━━━━━━┳━━━━━━━━━┓                                                                                      │</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">│ ┃</span><span style=\"background-color: #e7dfeb; font-weight: bold\"> Role </span><span style=\"background-color: #e7dfeb\">┃</span><span style=\"background-color: #e7dfeb; font-weight: bold\"> Content </span><span style=\"background-color: #e7dfeb\">┃                                                                                      │</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">│ ┡━━━━━━╇━━━━━━━━━┩                                                                                      │</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">│ └──────┴─────────┘                                                                                      │</span> │\n",
       "    │ <span style=\"background-color: #e7dfeb\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span> │\n",
       "    │ <span style=\"background-color: #f5f5dc\">╭──────────────────────────────────────────── Raw LLM Output ─────────────────────────────────────────────╮</span> │\n",
       "    │ <span style=\"background-color: #f5f5dc\">│  {\"translated_statement\": \"I hate you.\"}                                                                │</span> │\n",
       "    │ <span style=\"background-color: #f5f5dc\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span> │\n",
       "    │ <span style=\"background-color: #f0fff0\">╭─────────────────────────────────────────── Validated Output ────────────────────────────────────────────╮</span> │\n",
       "    │ <span style=\"background-color: #f0fff0\">│ {}                                                                                                      │</span> │\n",
       "    │ <span style=\"background-color: #f0fff0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span> │\n",
       "    ╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Logs\n",
       "└── ╭────────────────────────────────────────────────── Step 0 ───────────────────────────────────────────────────╮\n",
       "    │ \u001b[48;2;240;248;255m╭─\u001b[0m\u001b[48;2;240;248;255m───────────────────────────────────────────────\u001b[0m\u001b[48;2;240;248;255m Prompt \u001b[0m\u001b[48;2;240;248;255m────────────────────────────────────────────────\u001b[0m\u001b[48;2;240;248;255m─╮\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m                                                                                                       \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m    \u001b[0m\u001b[48;2;240;248;255m                                                                                                   \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m                                                                                                       \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255mHuman: Translate the given statement into English language:\u001b[0m\u001b[48;2;240;248;255m                                            \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m    Ich hasse dich.\u001b[0m\u001b[48;2;240;248;255m                                                                                    \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m    \u001b[0m\u001b[48;2;240;248;255m                                                                                                   \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255mGiven below is XML that describes the information to extract from this document and the tags to extract\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255mit into.\u001b[0m\u001b[48;2;240;248;255m                                                                                               \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m                                                                                                       \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m<output>\u001b[0m\u001b[48;2;240;248;255m                                                                                               \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m    <string description=\"Translate to English\" format=\"is-profanity-free\" name=\"translated_statement\"/>\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m</output>\u001b[0m\u001b[48;2;240;248;255m                                                                                              \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m                                                                                                       \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m                                                                                                       \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255mONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m`name` attribute of the corresponding XML, and the value is of the type specified by the corresponding \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255mXML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. \u001b[0m\u001b[48;2;240;248;255m      \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255mrequests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, \u001b[0m\u001b[48;2;240;248;255m   \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255menter `null`.\u001b[0m\u001b[48;2;240;248;255m                                                                                          \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m                                                                                                       \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255mHere are examples of simple (XML, JSON) pairs that show the expected behavior:\u001b[0m\u001b[48;2;240;248;255m                         \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m- `<string name='foo' format='two-words lower-case' />` => `{'foo': 'example one'}`\u001b[0m\u001b[48;2;240;248;255m                    \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m- `<list name='bar'><string format='upper-case' /></list>` => `{\"bar\": ['STRING ONE', 'STRING TWO', \u001b[0m\u001b[48;2;240;248;255m   \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255metc.]}`\u001b[0m\u001b[48;2;240;248;255m                                                                                                \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m- `<object name='baz'><string name=\"foo\" format=\"capitalize two-words\" /><integer name=\"index\" \u001b[0m\u001b[48;2;240;248;255m        \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255mformat=\"1-indexed\" /></object>` => `{'baz': {'foo': 'Some String', 'index': 1}}`\u001b[0m\u001b[48;2;240;248;255m                       \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m                                                                                                       \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m    \u001b[0m\u001b[48;2;240;248;255m                                                                                                   \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m                                                                                                       \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255mAssistant:\u001b[0m\u001b[48;2;240;248;255m                                                                                             \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m│\u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m    \u001b[0m\u001b[48;2;240;248;255m                                                                                                   \u001b[0m\u001b[48;2;240;248;255m \u001b[0m\u001b[48;2;240;248;255m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;248;255m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m╭─\u001b[0m\u001b[48;2;231;223;235m───────────────────────────────────────────\u001b[0m\u001b[48;2;231;223;235m Message History \u001b[0m\u001b[48;2;231;223;235m───────────────────────────────────────────\u001b[0m\u001b[48;2;231;223;235m─╮\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m┏━━━━━━┳━━━━━━━━━┓\u001b[0m\u001b[48;2;231;223;235m                                                                                     \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m┃\u001b[0m\u001b[1;48;2;231;223;235m \u001b[0m\u001b[1;48;2;231;223;235mRole\u001b[0m\u001b[1;48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m┃\u001b[0m\u001b[1;48;2;231;223;235m \u001b[0m\u001b[1;48;2;231;223;235mContent\u001b[0m\u001b[1;48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m┃\u001b[0m\u001b[48;2;231;223;235m                                                                                     \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m┡━━━━━━╇━━━━━━━━━┩\u001b[0m\u001b[48;2;231;223;235m                                                                                     \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m│\u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m└──────┴─────────┘\u001b[0m\u001b[48;2;231;223;235m                                                                                     \u001b[0m\u001b[48;2;231;223;235m \u001b[0m\u001b[48;2;231;223;235m│\u001b[0m │\n",
       "    │ \u001b[48;2;231;223;235m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m │\n",
       "    │ \u001b[48;2;245;245;220m╭─\u001b[0m\u001b[48;2;245;245;220m───────────────────────────────────────────\u001b[0m\u001b[48;2;245;245;220m Raw LLM Output \u001b[0m\u001b[48;2;245;245;220m────────────────────────────────────────────\u001b[0m\u001b[48;2;245;245;220m─╮\u001b[0m │\n",
       "    │ \u001b[48;2;245;245;220m│\u001b[0m\u001b[48;2;245;245;220m \u001b[0m\u001b[48;2;245;245;220m {\"translated_statement\": \"I hate you.\"}\u001b[0m\u001b[48;2;245;245;220m                                                               \u001b[0m\u001b[48;2;245;245;220m \u001b[0m\u001b[48;2;245;245;220m│\u001b[0m │\n",
       "    │ \u001b[48;2;245;245;220m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m │\n",
       "    │ \u001b[48;2;240;255;240m╭─\u001b[0m\u001b[48;2;240;255;240m──────────────────────────────────────────\u001b[0m\u001b[48;2;240;255;240m Validated Output \u001b[0m\u001b[48;2;240;255;240m───────────────────────────────────────────\u001b[0m\u001b[48;2;240;255;240m─╮\u001b[0m │\n",
       "    │ \u001b[48;2;240;255;240m│\u001b[0m\u001b[48;2;240;255;240m \u001b[0m\u001b[48;2;240;255;240m{}\u001b[0m\u001b[48;2;240;255;240m                                                                                                     \u001b[0m\u001b[48;2;240;255;240m \u001b[0m\u001b[48;2;240;255;240m│\u001b[0m │\n",
       "    │ \u001b[48;2;240;255;240m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m │\n",
       "    ╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(guard_metric.state.most_recent_call.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67787988-6bca-4840-8746-715c85ce7b3a",
   "metadata": {},
   "source": [
    "There are certain metrics that are so common, that pre-built validators were created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a62c8f-add1-4040-a403-aecc9fc4ff80",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Write a custom metric-based guardrail or use some of the pre-built <a href=https://docs.guardrailsai.com/api_reference/validators/>Guardrail.ai validators</a>.</b>\n",
    "You can load them in with <code>from guardrails.validators import IsProfanityFree, RemoveRedundantSentences, ValidLength</code>.\n",
    "</div>\n",
    "<img style=\"display: block; margin-left: auto; margin-right: auto;\" src=\"./images/activity.png\" alt=\"Activity\" width=\"125\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0492b2fc-52d7-48c2-a121-8cc5c151aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## CODE HERE ####################\n",
    "\n",
    "\n",
    "############## END OF CODE ##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a045b85-6584-4d52-8535-6c2c5eaa8529",
   "metadata": {},
   "source": [
    "### <a name=\"33\">3.3. LLM-based and model-based filtering</a>\n",
    "(<a href=\"#3\">Go to \"Guardrails\"</a>)\n",
    "\n",
    "LLM-based filtering utilizes another LLM to determine the intent of the request; if the helper LLM finds that the prompt is malicious, the prompt will be rejected and not sent to the real LLM. To set this up, the output of one LLM needs to be provided as input to the next LLM - this is called **prompt chaining**. Careful, as doing this in a production scenario with thousands of requests might incur significant cost, latency issues and cannot guarantee that harm will be prevented. \n",
    "\n",
    "#### Prompt chaining using LLMs\n",
    "Prompt chaining is a method of using LLMs to accomplish a task by breaking it into multiple smaller prompts and passing the output of one prompt as the input to the next. Chaining multiple prompts can help achieve a desired format and quality in the generated text. The very first model in the chain should be an intent classifier, such as [Cohere's Intent Recognition](https://docs.cohere.com/reference/intent-recognition)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3710b509-f4a7-49bb-a22b-7475d2cf9df4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Write a simple class or method that passes a prompt through a classifier with an added decision criteria that determines whether or not the prompt should be returned to user, rephrased or filtered.</b>\n",
    "</div>\n",
    "<img style=\"display: block; margin-left: auto; margin-right: auto;\" src=\"./images/activity.png\" alt=\"Activity\" width=\"125\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69419b5b-2fad-4104-b4bf-b63f4b86d852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############## CODE HERE ####################\n",
    "\n",
    "\n",
    "############## END OF CODE ##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fedcbce-f11c-4995-aff7-ec5fd22abb52",
   "metadata": {},
   "source": [
    "#### Preventing prompt leakage example\n",
    "Prompt leaking is another type of prompt injection where prompt attacks are designed to leak details from the prompt which could contain confidential or proprietary information that was not intended for the public. Using Amazon Comprehend, you will add a `AmazonComprehendModerationChain` moderation which requires some configuration to configuring the behavior of the PII validations: `ModerationPiiConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4a59a6a-9c24-421e-a533-ed8e4fd653af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.comprehend_moderation import (\n",
    "    AmazonComprehendModerationChain,\n",
    "    ModerationPiiConfig,\n",
    ")\n",
    "\n",
    "comprehend_client = boto3.client(\"comprehend\", region_name=\"us-east-1\")\n",
    "\n",
    "pii_config = ModerationPiiConfig(labels=[\"SSN\"], redact=True, mask_character=\"X\")\n",
    "\n",
    "comprehend_moderation = AmazonComprehendModerationChain(\n",
    "    moderation_config=pii_config, client=comprehend_client, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d8d134-5122-4fe7-9029-817d46b5d30d",
   "metadata": {},
   "source": [
    "\n",
    "In addition to the moderation chain, you  need a fake LLM class that can be used for testing. This allows you to mock out calls to the LLM and simulate what would happen if the LLM responded in a certain way. LangChain provides this as `FakeListLLM`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40c4f64b-7abc-45ee-beba-b79253f9dbf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AmazonComprehendModerationChain chain...\u001b[0m\n",
      "Running AmazonComprehendModerationChain...\n",
      "Running pii Validation...\n",
      "Found PII content..stopping..\n",
      "The prompt contains PII entities and cannot be processed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The prompt contains PII entities and cannot be processed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The prompt contains PII entities and cannot be processed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.fake import FakeListLLM\n",
    "from langchain_experimental.comprehend_moderation.base_moderation_exceptions import (\n",
    "    ModerationPiiError,\n",
    ")\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "responses = [\n",
    "    \"Final Answer: A credit card number looks like 1289-2321-1123-2387. A fake SSN number looks like 323-22-9980. John Doe's phone number is (999)253-9876.\",\n",
    "    # replace with your own expletive\n",
    "    \"Final Answer: This is a really <expletive> way of constructing a birdhouse. This is <expletive> insane to think that any birds would actually create their <expletive> nests here.\",\n",
    "]\n",
    "\n",
    "llm = FakeListLLM(responses=responses)\n",
    "\n",
    "pii_chain = (\n",
    "    prompt\n",
    "    | comprehend_moderation\n",
    "    | {\"input\": (lambda x: x[\"output\"]) | llm}\n",
    "    | comprehend_moderation\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = pii_chain.invoke(\n",
    "        {\n",
    "            \"question\": \"A sample SSN number looks like this 123-45-7890. Can you give me some more samples?\"\n",
    "        }\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(str(e))\n",
    "else:\n",
    "    print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f7e869-db17-4815-b8d7-1f501c93454d",
   "metadata": {},
   "source": [
    "## <a name=\"4\">4. Conclusion</a>\n",
    "\n",
    "- Use clear and specific instructions. The prompt should be clear and specific about what you are asking the LLM to do. This will help to avoid ambiguity and ensure that the LLM generates a relevant and unbiased response.\n",
    "- Segregate external content from user prompts. Separate and denote where untrusted content is being used to limit their influence on user prompts. \n",
    "- Use a variety of prompts. Don’t just use the same prompt every time. This will help to ensure that the LLM is exposed to a variety of viewpoints and doesn’t become biased towards any one particular perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf63f5-f18d-41eb-bd2e-19d2fd086e43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Additional resources\n",
    "- https://github.com/microsoft/promptbench\n",
    "- https://www.promptingguide.ai/techniques\n",
    "- https://github.com/uptrain-ai/uptrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1f2a8b-51ba-4f64-a529-b12c0d388ed1",
   "metadata": {},
   "source": [
    "# Thank you!\n",
    "\n",
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"images/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
