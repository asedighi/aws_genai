{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea92ff31-bfbb-4da5-b7d8-4e0b58528fe7",
   "metadata": {},
   "source": [
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"images/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>\n",
    "\n",
    "\n",
    "# <a name=\"0\">MLU Advanced Prompt Engineering for LLMs</a>\n",
    "## <a name=\"0\">Lab 7: Watermarking</a>\n",
    "\n",
    "This notebook demonstrates how to use various techniques that can help improve the safety and security of LLM-backed applications. The coding examples cover watermarking as an authentication technique. \n",
    "\n",
    "1. <a href=\"#1\">Install and import libraries</a>\n",
    "2. <a href=\"#2\">Watermarking for authentication</a>\n",
    "4. <a href=\"#3\">Conclusion</a>\n",
    "\n",
    "    \n",
    "Please work top to bottom of this notebook and don't skip sections as this could lead to error messages due to missing code.\n",
    "\n",
    "---\n",
    "\n",
    "<br/>\n",
    "You will be presented with coding activities to check your knowledge and understanding throughout the notebook whenever you see the MLU robot:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45807b08-06db-49d7-8cc4-4edae4ddcbaf",
   "metadata": {},
   "source": [
    "<img style=\"display: block; margin-left: auto; margin-right: auto;\" src=\"./images/activity.png\" alt=\"Activity\" width=\"125\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc1675-295d-4b62-908c-d87ac9e241f4",
   "metadata": {},
   "source": [
    "## <a name=\"1\">1. Install and import libraries</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's start by installing all required packages as specified in the `requirements.txt` file and importing several libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc03394-3d26-47e0-8561-f235923bcf7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q --upgrade pip\n",
    "!pip3 install -r requirements.txt --quiet\n",
    "!rm -rf lm-watermarking\n",
    "!git clone https://github.com/jwkirchenbauer/lm-watermarking.git --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef767883-c218-4b89-9a6d-95f026c95341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings, sys\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"/home/ec2-user/SageMaker/WKSP-Adv-Prompt-Eng/lm-watermarking/\")\n",
    "\n",
    "import json\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7bbfd6-b9bb-468b-92ac-547f8664e8aa",
   "metadata": {},
   "source": [
    "## <a name=\"2\">2. Watermarking for authentication</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Potential harms of LLMs can be mitigated by watermarking model output, i.e., **embedding signals into generated text that are invisible to humans but algorithmically detectable from a short span of tokens**. Watermarks can be embedded with negligible impact on text quality, and can be detected using efficient open-source algorithms without access to the language model API or model parameters. The watermark works by selecting a randomized set of \"green\" tokens before a word is generated, and then softly promoting use of green tokens during sampling. For more details about watermarks for LLMs have a look at the paper [A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226).\n",
    "\n",
    "First, you need to load in a tokenizer and model that allows access to the tokens and associated logit values. This means, you will need to use a Huggingface ðŸ¤— or other third-party LLM that you can run locally. Bedrock-hosted models can be queried but not downloaded, thus they are not apt for this demo.\n",
    "\n",
    "The following uses a tiny LLM, [`dlite-v2-124m`](https://huggingface.co/aisquared/dlite-v2-124m), derived from OpenAI's smallest GPT-2 model and fine-tuned on a single GPU. `dlite-v2-124m` is **not a state-of-the-art model**. We are using it here to demonstrate watermarking in a lean setup with a CPU instance. If you have access to larger, GPU-enabled instances, feel free to try larger models available in Huggingface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e80c454-7e49-4be5-af82-851e69040dd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f3be947df34a2cb05c7604e008a169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)-124m/resolve/main/tokenizer_config.json:   0%|          | 0.00/255 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac85f4dde6bf4136a57e1f3f8ab1bf7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)ed/dlite-v2-124m/resolve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89eb963b867245e48d0d0c15864b1893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)lite-v2-124m/resolve/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c089024112604dbfa7dda0ff9af4bea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)e-v2-124m/resolve/main/added_tokens.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ceff0b98494a8c9255f1ac9381a24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)24m/resolve/main/special_tokens_map.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e85f817e0cc479986bec6af7af9029e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)d/dlite-v2-124m/resolve/main/config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb892ea90e2e48568362fd2173c1e541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/262M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch \n",
    "\n",
    "model_id = \"aisquared/dlite-v2-124m\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    padding_side=\"left\",\n",
    "    device_map='auto'\n",
    ")\n",
    "tokenizer.eos_token_id  = tokenizer.pad_token_id\n",
    "\n",
    "# Load tiny model in BF16 precision\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360fd1b-9910-4110-a7ac-d8da87274288",
   "metadata": {},
   "source": [
    "With the model and tokenizer you can now generate output tokens and pass the logits values to the watermark processor that will add certain random tokens. `WatermarkLogitsProcessor` loads a ðŸ¤— language model that can perform text generation via `model.generate`, and prepares to call the generation method with a special LogitsProcessor that implements watermarking at the current hyperparameter values. The most important parameters to specify are:\n",
    "- `gamma`: Gamma denotes the fraction of the vocabulary that will be in each green list. \n",
    "- `delta`: The magnitude of the logit bias delta determines the strength of the watermark. \n",
    "\n",
    "As a baseline generation setting, default values of `gamma=0.25` and `delta=2.0` are suggested. Reduce `delta` if text quality is negatively impacted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6205cd86-ad60-4f22-88b1-2d8aa41156e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from extended_watermark_processor import WatermarkLogitsProcessor\n",
    "from transformers import LogitsProcessorList\n",
    "\n",
    "# instantiate watermarking processor\n",
    "watermark_processor = WatermarkLogitsProcessor(\n",
    "    vocab=list(tokenizer.get_vocab().values()),\n",
    "    gamma=0.25,\n",
    "    delta=2.0,\n",
    "    seeding_scheme=\"selfhash\",\n",
    ")\n",
    "\n",
    "# tokenize input\n",
    "tokenized_input = tokenizer(\"What did you do today?\", return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# generate output tokens and parse through watermarking\n",
    "output_tokens = model.generate(\n",
    "    **tokenized_input,\n",
    "    pad_token_id=50256,\n",
    "    logits_processor=LogitsProcessorList([watermark_processor])\n",
    ")\n",
    "\n",
    "# isolate newly generated tokens as only those are watermarked, the input/prompt is not\n",
    "output_tokens = output_tokens[:, tokenized_input[\"input_ids\"].shape[-1] :]\n",
    "\n",
    "# convert back to text\n",
    "output_text = tokenizer.batch_decode(output_tokens, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c92db4-0c0a-41c8-a8bc-3addd164e208",
   "metadata": {},
   "source": [
    "Have a look at the resulting text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0982afbe-21f9-4a66-8209-0c3cd8aec267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "I was born on March 31st, 1891.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a61152-7a48-4f3e-a557-6981be4b29af",
   "metadata": {},
   "source": [
    "Let's now try to detect the watermarked text. \n",
    "\n",
    "The `WatermarkDetector` is the detector for all watermarks imprinted with `WatermarkLogitsProcessor`. It needs to be given the exact same settings that were given during text generation  to replicate the watermark greenlist generation and so detect the watermark. This includes the correct device that was used during text generation, the correct tokenizer, the correct seeding_scheme name, and parameters.\n",
    "\n",
    "The detector below shows a high confidence that the input text has been watermarked.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83086e69-3917-4d48-9508-8d210c523c44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_tokens_scored': 11,\n",
       " 'num_green_tokens': 10,\n",
       " 'green_fraction': 0.9090909090909091,\n",
       " 'z_score': 5.048252022715237,\n",
       " 'p_value': 2.2293536093864233e-07,\n",
       " 'z_score_at_T': tensor([1.7321, 2.4495, 3.0000, 3.4641, 3.8730, 4.2426, 3.7097, 4.0825, 4.4264,\n",
       "         4.7469, 5.0483]),\n",
       " 'prediction': True,\n",
       " 'confidence': 0.999999777064639}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from extended_watermark_processor import WatermarkDetector\n",
    "\n",
    "watermark_detector = WatermarkDetector(\n",
    "    vocab=list(tokenizer.get_vocab().values()),\n",
    "    gamma=0.25,  # should match original setting\n",
    "    seeding_scheme=\"selfhash\",  # should match original setting\n",
    "    device=model.device,  # must match the original rng device type\n",
    "    tokenizer=tokenizer,\n",
    "    z_threshold=4.0,\n",
    "    normalizers=[],\n",
    "    ignore_repeated_ngrams=True,\n",
    ")\n",
    "\n",
    "score_dict = watermark_detector.detect(\n",
    "    output_text\n",
    ")  # or any other text of interest to analyze\n",
    "\n",
    "score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2363c7-e3fd-489b-889d-757eea733d92",
   "metadata": {},
   "source": [
    "Now compare with the watermarker detector acting on regularly generated text. In this case, the detector correctly predicts that the text is not watermarked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f01b759-8305-4719-94ce-8fcf361b3988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_tokens_scored': 11,\n",
       " 'num_green_tokens': 3,\n",
       " 'green_fraction': 0.2727272727272727,\n",
       " 'z_score': 0.17407765595569785,\n",
       " 'p_value': 0.4309022165245054,\n",
       " 'z_score_at_T': tensor([-0.5774, -0.8165, -1.0000, -1.1547, -1.2910, -1.4142, -1.5275, -0.8165,\n",
       "         -0.9623, -0.3651,  0.1741]),\n",
       " 'prediction': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize input\n",
    "tokenized_input = tokenizer(\"What did you do today?\", return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# generate output tokens and parse through watermarking\n",
    "output_tokens = model.generate(\n",
    "    **tokenized_input,\n",
    "    pad_token_id=50256,\n",
    ")\n",
    "\n",
    "# isolate newly generated tokens as only those are watermarked, the input/prompt is not\n",
    "output_tokens = output_tokens[:, tokenized_input[\"input_ids\"].shape[-1] :]\n",
    "\n",
    "# convert back to text\n",
    "output_text = tokenizer.batch_decode(output_tokens, skip_special_tokens=True)[0]\n",
    "\n",
    "score_dict = watermark_detector.detect(output_text)\n",
    "\n",
    "score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff43f3-9703-43de-b4c8-23eb1ef2ade2",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Try your own prompt and add a watermark authentication to it.</b> Also try to change the different parameters for <code>WatermarkLogitsProcessor</code> to see how the output is changing.<br/><br/>\n",
    "<b>Note:</b> due to the limited capabilities of the <code>dlite-v2-124m</code> model, not all experiments might work. You can try more capable LLMs if you have access to larger instances to run them. \n",
    "</div>\n",
    "<img style=\"display: block; margin-left: auto; margin-right: auto;\" src=\"./images/activity.png\" alt=\"Activity\" width=\"125\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6571aec7-68d2-4027-9eee-ca9e6d115003",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## CODE HERE ####################\n",
    "\n",
    "\n",
    "############## END OF CODE ##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f7e869-db17-4815-b8d7-1f501c93454d",
   "metadata": {},
   "source": [
    "## <a name=\"3\">3. Conclusion</a>\n",
    "\n",
    "- Enforce privilege control on LLM access to backend systems. Provide the LLM with its own API tokens for extensible functionality, such as plugins, data access, and function-level permissions.\n",
    "- Use watermarking to monitor and audit the use and impact of LLMs and prevent misuse or abuse. \n",
    "- Watermarks are embedded uniformly across different tasks, and may not perform well for certain tasks where specific tokens have more semantic importance than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf63f5-f18d-41eb-bd2e-19d2fd086e43",
   "metadata": {},
   "source": [
    "### Additional resources\n",
    "- https://github.com/microsoft/promptbench\n",
    "- https://www.promptingguide.ai/techniques\n",
    "- https://github.com/uptrain-ai/uptrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebd5d9d-dfa7-419e-9da7-23f3ee00d596",
   "metadata": {},
   "source": [
    "# Thank you!\n",
    "\n",
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"images/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
